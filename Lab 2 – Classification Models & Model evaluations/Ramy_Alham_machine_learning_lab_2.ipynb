{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgnme7zF9UNW",
        "outputId": "0cc36ca7-2e51-4964-e2ef-fcf4a6d0a08e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.21.6)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install numpy\n",
        "! pip install pandas \n",
        "! pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UfGM0h2cA3gI"
      },
      "outputs": [],
      "source": [
        "#importing libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 1"
      ],
      "metadata": {
        "id": "scSWvYxEdOtq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "YbISCF7JA8qF",
        "outputId": "3229d8d1-b646-42ec-d8e0-1e0cd63bc16a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Petal Length  Petal Width  Sepal Length  Sepal Width  Species Type\n",
              "0           5.1          3.5           1.4           0.2  Iris-setosa\n",
              "1           4.9          3.0           1.4           0.2  Iris-setosa\n",
              "2           4.7          3.2           1.3           0.2  Iris-setosa\n",
              "3           4.6          3.1           1.5           0.2  Iris-setosa\n",
              "4           5.0          3.6           1.4           0.2  Iris-setosa\n",
              "5           5.4          3.9           1.7           0.4  Iris-setosa\n",
              "6           4.6          3.4           1.4           0.3  Iris-setosa\n",
              "7           5.0          3.4           1.5           0.2  Iris-setosa\n",
              "8           4.4          2.9           1.4           0.2  Iris-setosa\n",
              "9           4.9          3.1           1.5           0.1  Iris-setosa"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-60796df1-4dfe-4b1f-a3e7-9e28ff7f2191\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Petal Length</th>\n",
              "      <th>Petal Width</th>\n",
              "      <th>Sepal Length</th>\n",
              "      <th>Sepal Width</th>\n",
              "      <th>Species Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5.4</td>\n",
              "      <td>3.9</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.4</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.3</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>4.4</td>\n",
              "      <td>2.9</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.1</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-60796df1-4dfe-4b1f-a3e7-9e28ff7f2191')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-60796df1-4dfe-4b1f-a3e7-9e28ff7f2191 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-60796df1-4dfe-4b1f-a3e7-9e28ff7f2191');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "from pandas import read_csv\n",
        "def load_data(filepath: str) -> pd.DataFrame:\n",
        "#define a function that takes the file path, and then return the data.\n",
        "  column_names = ['Petal Length', 'Petal Width', 'Sepal Length', 'Sepal Width ', 'Species Type']#gives names to column\n",
        "  #data = read_csv(filepath, header=None, names=column_names, sep=\"\\s+\")#read the file and skip the first 22 rows, and give the name of the cloumn\n",
        "  #data1=pd.DataFrame(data=data)\n",
        "  data = pd.read_csv(filepath, names=column_names)\n",
        "  data1=pd.DataFrame(data)\n",
        "\n",
        "  return data1\n",
        "\n",
        "data1 = load_data('iris.data')\n",
        "data1.head(10)#show the head of the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSo7pKFLHKpU",
        "outputId": "799d3996-db64-4783-f26c-107079dd5471"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 150 entries, 0 to 149\n",
            "Data columns (total 5 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   Petal Length  150 non-null    float64\n",
            " 1   Petal Width   150 non-null    float64\n",
            " 2   Sepal Length  150 non-null    float64\n",
            " 3   Sepal Width   150 non-null    float64\n",
            " 4   Species Type  150 non-null    object \n",
            "dtypes: float64(4), object(1)\n",
            "memory usage: 6.0+ KB\n"
          ]
        }
      ],
      "source": [
        "data1.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmGhYnBgHldM"
      },
      "source": [
        "Question 2: adding target column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "a5cWqBePINmH",
        "outputId": "416d9227-dac6-4dc2-db97-49930c403bc5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Petal Length  Petal Width  Sepal Length  Sepal Width  Species Type  target\n",
              "0           5.1          3.5           1.4           0.2  Iris-setosa       1\n",
              "1           4.9          3.0           1.4           0.2  Iris-setosa       1\n",
              "2           4.7          3.2           1.3           0.2  Iris-setosa       1\n",
              "3           4.6          3.1           1.5           0.2  Iris-setosa       1\n",
              "4           5.0          3.6           1.4           0.2  Iris-setosa       1\n",
              "5           5.4          3.9           1.7           0.4  Iris-setosa       1\n",
              "6           4.6          3.4           1.4           0.3  Iris-setosa       1\n",
              "7           5.0          3.4           1.5           0.2  Iris-setosa       1\n",
              "8           4.4          2.9           1.4           0.2  Iris-setosa       1\n",
              "9           4.9          3.1           1.5           0.1  Iris-setosa       1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f8b48c5c-ba3d-48c8-8123-6459a73ed89e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Petal Length</th>\n",
              "      <th>Petal Width</th>\n",
              "      <th>Sepal Length</th>\n",
              "      <th>Sepal Width</th>\n",
              "      <th>Species Type</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5.4</td>\n",
              "      <td>3.9</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.4</td>\n",
              "      <td>Iris-setosa</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.3</td>\n",
              "      <td>Iris-setosa</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>4.4</td>\n",
              "      <td>2.9</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.1</td>\n",
              "      <td>Iris-setosa</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f8b48c5c-ba3d-48c8-8123-6459a73ed89e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f8b48c5c-ba3d-48c8-8123-6459a73ed89e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f8b48c5c-ba3d-48c8-8123-6459a73ed89e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "target = []\n",
        "\n",
        "for i in range(len(data1['Species Type'])):\n",
        "    if data1['Species Type'][i] == ('Iris-setosa'):\n",
        "        target.append(1)\n",
        "    else:\n",
        "        target.append(0)\n",
        "\n",
        "data1['target'] = target\n",
        "\n",
        "data1.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "z-9ttO3QnHvr",
        "outputId": "5a716fa0-26f3-4993-83f7-864d94c57759"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Petal Length  Petal Width  Sepal Length  Sepal Width       target\n",
              "count    150.000000   150.000000    150.000000    150.000000  150.000000\n",
              "mean       5.843333     3.054000      3.758667      1.198667    0.333333\n",
              "std        0.828066     0.433594      1.764420      0.763161    0.472984\n",
              "min        4.300000     2.000000      1.000000      0.100000    0.000000\n",
              "25%        5.100000     2.800000      1.600000      0.300000    0.000000\n",
              "50%        5.800000     3.000000      4.350000      1.300000    0.000000\n",
              "75%        6.400000     3.300000      5.100000      1.800000    1.000000\n",
              "max        7.900000     4.400000      6.900000      2.500000    1.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-83d2dc03-72c5-430a-b950-cdc5990c8d90\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Petal Length</th>\n",
              "      <th>Petal Width</th>\n",
              "      <th>Sepal Length</th>\n",
              "      <th>Sepal Width</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>150.000000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>150.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5.843333</td>\n",
              "      <td>3.054000</td>\n",
              "      <td>3.758667</td>\n",
              "      <td>1.198667</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.828066</td>\n",
              "      <td>0.433594</td>\n",
              "      <td>1.764420</td>\n",
              "      <td>0.763161</td>\n",
              "      <td>0.472984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>4.300000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>5.100000</td>\n",
              "      <td>2.800000</td>\n",
              "      <td>1.600000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5.800000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.350000</td>\n",
              "      <td>1.300000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.400000</td>\n",
              "      <td>3.300000</td>\n",
              "      <td>5.100000</td>\n",
              "      <td>1.800000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>7.900000</td>\n",
              "      <td>4.400000</td>\n",
              "      <td>6.900000</td>\n",
              "      <td>2.500000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-83d2dc03-72c5-430a-b950-cdc5990c8d90')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-83d2dc03-72c5-430a-b950-cdc5990c8d90 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-83d2dc03-72c5-430a-b950-cdc5990c8d90');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "data1.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMoncvbKLnfO",
        "outputId": "12c73825-6a69-4a19-c7cc-0139e302392b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "target\n",
              "0    100\n",
              "1     50\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "data1.groupby('target').size()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3: splitting the data\n",
        "\n",
        "I used 2 differnt way to split the data, one is tall and ths second is small"
      ],
      "metadata": {
        "id": "1gJnVDzud5Xe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8pzpGPG__iD",
        "outputId": "b8d99583-8549-406c-c369-e2951e8ee3b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train data contain: target\n",
            "0    70\n",
            "1    35\n",
            "dtype: int64\n",
            "validation data contain:  target\n",
            "0    10\n",
            "1     5\n",
            "dtype: int64\n",
            "test data contain: target\n",
            "0    20\n",
            "1    10\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#first method to split the data\n",
        "#Spliting positive and negative sample\n",
        "data1_positive=data1.loc[data1['target'] == 1]# splitting the data to positive if target=1\n",
        "data1_negative=data1.loc[data1['target'] == 0]#splitting the data to negative if taregt=0\n",
        "#data1_negative.reset_index(drop=True, inplace=True)# Reset the raw index for negative data because the raws begin from index 50, not it begin from index 0\n",
        "\n",
        "#for train data:\n",
        "n_train= int((70/100)*150)#number of data of train\n",
        "n_train_pos= int(n_train*(1/3))#number of positive data in train data\n",
        "n_train_neg= (n_train-n_train_pos)#number of negative data in train data\n",
        "train_data_pos=data1_positive[0:n_train_pos]\n",
        "train_data_neg=data1_negative[0:n_train_neg]\n",
        "train_data=pd.concat([train_data_pos, train_data_neg], ignore_index=True, axis=0)# add the positive and negaive data together\n",
        "train_data = train_data.sample(n_train)# random the samples to random the positive and negative \n",
        "\n",
        "#for validation data:\n",
        "n_valid=int(10/100*150)#number of data of validation\n",
        "n_valid_pos=int(n_valid*(1/3))#number of positive data in validation data\n",
        "n_valid_neg= (n_valid-n_valid_pos)#number of negative data in validation data\n",
        "valid_data_pos=data1_positive[n_train_pos:n_train_pos+n_valid_pos]\n",
        "valid_data_neg=data1_negative[n_train_neg:n_train_neg+n_valid_neg]\n",
        "valid_data=pd.concat([valid_data_pos, valid_data_neg], ignore_index=True, axis=0)# add the positive and negaive data together\n",
        "valid_data = valid_data.sample(n_valid)# random the samples to random the positive and negative \n",
        "\n",
        "#for testing data:\n",
        "n_test=int(20/100*150)#number of data of train\n",
        "n_test_pos=int(n_test*(1/3))#number of positive data in train data\n",
        "n_test_neg= (n_test-n_test_pos)#number of negative data in train data\n",
        "test_data_pos=data1_positive[n_train_pos+n_valid_pos:]\n",
        "test_data_neg=data1_negative[n_train_neg+n_valid_neg:]\n",
        "test_data=pd.concat([test_data_pos, test_data_neg], ignore_index=True, axis=0)# add the positive and negaive data together\n",
        "test_data = test_data.sample(n_test)# random the samples to random the positive and negative \n",
        "\n",
        "print(\"train data contain:\",train_data.groupby('target').size())# to check the train data\n",
        "print(\"validation data contain: \",valid_data.groupby('target').size())# to check the validation data\n",
        "print(\"test data contain:\",test_data.groupby('target').size())# to check the test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNTtXDj2cMKu",
        "outputId": "3715befc-0a9d-412b-f48b-3c43642b3a50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train data contain: target\n",
            "0    70\n",
            "1    35\n",
            "dtype: int64\n",
            "validation data contain:  target\n",
            "0    10\n",
            "1     5\n",
            "dtype: int64\n",
            "test data contain: target\n",
            "0    20\n",
            "1    10\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#another method to split the data\n",
        "data1_positive=data1.loc[data1['target'] == 1]# splitting the data to positive if target=1\n",
        "data1_negative=data1.loc[data1['target'] == 0]#splitting the data to negative if taregt=0\n",
        "\n",
        "train_data_pos,valid_data_pos,test_data_pos = data1_positive.iloc[:35],data1_positive.iloc[35:40],data1_positive.iloc[40:50]\n",
        "train_data_neg,valid_data_neg,test_data_neg=data1_negative.iloc[:70],data1_negative.iloc[70:80],data1_negative.iloc[80:100]\n",
        "\n",
        "train_data=pd.concat([train_data_pos, train_data_neg], ignore_index=True, axis=0)# add the positive and negaive data together\n",
        "train_data = train_data.sample(105)# random the samples to random the positive and negative \n",
        "\n",
        "valid_data=pd.concat([valid_data_pos, valid_data_neg], ignore_index=True, axis=0)# add the positive and negaive data together\n",
        "valid_data = valid_data.sample(15)# random the samples to random the positive and negative\n",
        "\n",
        "test_data=pd.concat([test_data_pos, test_data_neg], ignore_index=True, axis=0)# add the positive and negaive data together\n",
        "test_data = test_data.sample(30)# random the samples to random the positive and negative \n",
        "\n",
        "print(\"train data contain:\",train_data.groupby('target').size())# to check the train data\n",
        "print(\"validation data contain: \",valid_data.groupby('target').size())# to check the validation data\n",
        "print(\"test data contain:\",test_data.groupby('target').size())# to check the test data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4:\n",
        "\n",
        "I used Two method to calculate the prectected value."
      ],
      "metadata": {
        "id": "AnGCJvbGeTVK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gamUmvbRTDIR",
        "outputId": "df9e3a3d-15fe-488e-9072-1598ad08935f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 1 1 0 0 1 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 0 1 1 0 1 0 0]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(105, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "#select the two columns from the Iris dataset\n",
        "train_x=train_data[['Petal Width','Petal Length']].to_numpy()# this is train data x, I just get the petal width and petal lenght as x \n",
        "train_y=train_data['target'].to_numpy()# take the target value as y\n",
        "\n",
        "valid_x=valid_data[['Petal Width','Petal Length']].to_numpy()\n",
        "valid_y=valid_data['target'].to_numpy()\n",
        "\n",
        "test_x=test_data[['Petal Width','Petal Length']].to_numpy()\n",
        "test_y=test_data['target'].to_numpy()\n",
        "\n",
        "print(test_y)\n",
        "train_x.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params_try = np.random.randn(3) # define my parameters as random, because i don't want it to update every time i call the function so i defined it outside the function"
      ],
      "metadata": {
        "id": "wVrl6O-anelO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used Two method to calculate the prectected value \n",
        ">firstly, i make it as functions\n",
        "\n",
        ">Secondly, I succeed to make the class.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "I4NDgNu0tgd0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bce(y, yhat):\n",
        "#apply  the  binary  cross  entropy  function  returning  the  loss\n",
        "  loss = (-((y * np.log(yhat)) + (1-y) * np.log(1-yhat)))\n",
        "  return loss"
      ],
      "metadata": {
        "id": "jkFyv2V3l4vD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def logistic(x):\n",
        "  # apply the logistic function\n",
        "    y=1/(1+(np.exp(-x)))\n",
        "    return y"
      ],
      "metadata": {
        "id": "y-AdaZE2l4sE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(x,params_try, logits=False):\n",
        "    # make the predict function that  takes the x value and paramters and returning the prediction value\n",
        "    yhat=params_try[0] + x @ params_try[1:].reshape(-1, 1)\n",
        "    if not logits:# if the value is not represents probability values from 0 to 1\n",
        "      yhat = logistic(yhat)\n",
        "    return np.array(yhat)"
      ],
      "metadata": {
        "id": "zxcQDZ3nl4oG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(params_try,train_x, train_y, valid_x, valid_y, epochs: int = 100, lr: float = 0.01):\n",
        "    \n",
        "# define a function that takes:\n",
        "# parameters and trainingg and validation data, and then returning the best parameters and train loss and validation loss\n",
        "    train_loss_series = []\n",
        "    valid_loss_series = []\n",
        "    params = params_try\n",
        "#train the model  using gradient descent and finite-differences\n",
        "# i just used the train data to update the parametrs \n",
        "    for epoch in range (1,epochs+1):\n",
        "\n",
        "        for xi,yi in zip(train_x,train_y):\n",
        "        # calculate  loss  and  update  model  parameters  using  gradient  descent\n",
        "            this_params = params\n",
        "            yhat = predict(xi,params)# use predict function to get the prediction value of y \n",
        "            curr_loss=bce(yi,yhat)# calculate the loss by calling  bce function \n",
        "            params_grads = []# define empty list of params_grad\n",
        "\n",
        "            params=this_params+np.array([lr, 0, 0]).reshape(this_params.shape)# the first number of  parametes + step i take the step same as the learning rate\n",
        "            yhat = predict(xi,params)#again predict the value of target using the new parametrs \n",
        "            train_loss = bce(yi, yhat)#calculate the loss by calling  bce function\n",
        "            params_grad=(train_loss-curr_loss)/lr # delta\n",
        "            params_grads.append(params_grad)# append the delta\n",
        "            \n",
        "\n",
        "            params=this_params+np.array([0, lr, 0]).reshape(this_params.shape)\n",
        "            yhat = predict(xi,params)\n",
        "            train_loss = bce(yi, yhat)\n",
        "            params_grad=(train_loss-curr_loss)/lr\n",
        "            params_grads.append(params_grad)\n",
        "\n",
        "            params=this_params+np.array([0, 0, lr]).reshape(this_params.shape)\n",
        "            yhat = predict(xi,params)\n",
        "            train_loss = bce(yi, yhat)\n",
        "            params_grad=(train_loss-curr_loss)/lr\n",
        "            params_grads.append(params_grad)\n",
        "            \n",
        "            params_grads = np.array(params_grads).reshape(this_params.shape)\n",
        "\n",
        "            params = this_params - lr*params_grads # update the parameters value\n",
        "\n",
        "        training_loss = 0\n",
        "        for xi,yi in zip(train_x,train_y):\n",
        "            yhat = predict(xi,params)\n",
        "            training_loss= training_loss + float(bce(yi,yhat)) # caluclate the training loss because i will use it in drawing \n",
        "        train_loss_series.append(training_loss) # append the trainiing losses values \n",
        "\n",
        "        validation_loss = 0\n",
        "        for xi,yi in zip(valid_x, valid_y):\n",
        "            yhat = predict(xi,params) \n",
        "            validation_loss = validation_loss + float(bce(yi,yhat)) # caluclate the validation loss because i will use it in drawing \n",
        "        valid_loss_series.append(validation_loss) # append the validation losses values \n",
        "\n",
        "    return params, np.array(train_loss_series), np.array(valid_loss_series) # rerturn these data \n"
      ],
      "metadata": {
        "id": "UV4U3_bnnop9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params, train_loss_series, valid_loss_series = fit(params_try,train_x, train_y, valid_x, valid_y, epochs=100, lr=0.3)\n"
      ],
      "metadata": {
        "id": "4D81pXL5xWbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "visulaize the data and I did'nt find any overfitting point:\n",
        "How can i know that the model is overfiiting?\n",
        "\n",
        "if the  plot of training loss continues to decrease, while the plot of validation loss decreases to a point and begins increasing again.\n",
        "\n",
        "I will make a loop to confirm that i don't have any overfitting\n"
      ],
      "metadata": {
        "id": "09tQBXmzCqy0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualise the training and validation loss.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(train_loss_series,label='train loss')\n",
        "plt.plot(valid_loss_series,label='valid loss')\n",
        "plt.legend (loc='best')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')"
      ],
      "metadata": {
        "id": "fznMFyZsp65y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to predict if there is an over fit or not \n",
        "valid_loss=valid_loss_series[0]\n",
        "for i in range (1,100):\n",
        "\n",
        "    if valid_loss_series[i]<valid_loss:\n",
        "        valid_loss=valid_loss_series[i]\n",
        "    else:\n",
        "        print('there is an overfit at',i)\n",
        "        break  \n",
        "\n",
        "# if doesnot print i value so no overfit happen"
      ],
      "metadata": {
        "id": "iZhdeTQBRc3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, i used the class instead of functions "
      ],
      "metadata": {
        "id": "QL-oWh7gE5Hk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# here, i use class, we will find as it's the same as functions but in brief and organized way.\n",
        "class LogisticRegressor:\n",
        "    def __init__(self, n_features: int = 2): \n",
        "        self.params = np.random.randn(n_features + 1)\n",
        "\n",
        "    def logistic(self, x):\n",
        "        #apply the logistic function\n",
        "        y=1/(1+(np.exp(-x)))\n",
        "        return y\n",
        "\n",
        "    def __call__(self, x, logits=False):\n",
        "        yhats = []\n",
        "        for xi in x:\n",
        "            yhat = self.predict(xi, logits)\n",
        "            yhats.append(yhat)\n",
        "        return np.array(yhats)\n",
        "\n",
        "    def fit(self, train_x, train_y, valid_x, valid_y, epochs: int = 100, lr: float = 0.01):\n",
        "        #train the model  using gradient descent and finite-differences\n",
        "        self.train_loss_series = []\n",
        "        self.valid_loss_series = []\n",
        "\n",
        "        for epoch in range (1,epochs+1):\n",
        "            # the same for i used before in function \n",
        "            for xi,yi in zip(train_x,train_y):\n",
        "                this_params = self.params\n",
        "                yhat = self.predict(xi)\n",
        "                curr_loss=bce(yi,yhat)\n",
        "                params_grads = []\n",
        "\n",
        "                self.params=this_params+np.array([lr, 0, 0]).reshape(this_params.shape)# the first number of  parametes +  learning rate i take it as step\n",
        "                yhat = self.predict(xi) #again predict the value of target \n",
        "                train_loss = bce(yi, yhat)#calculate the loss by calling  bce function\n",
        "                params_grad=(train_loss-curr_loss)/lr\n",
        "                params_grads.append(params_grad)\n",
        "\n",
        "                self.params=this_params+np.array([0, lr, 0]).reshape(this_params.shape)\n",
        "                yhat = self.predict(xi)\n",
        "                train_loss = bce(yi, yhat)\n",
        "                params_grad=(train_loss-curr_loss)/lr\n",
        "                params_grads.append(params_grad)\n",
        "\n",
        "                self.params=this_params+np.array([0, 0, lr]).reshape(this_params.shape)\n",
        "                yhat = self.predict(xi)\n",
        "                train_loss = bce(yi, yhat)\n",
        "                params_grad=(train_loss-curr_loss)/lr\n",
        "                params_grads.append(params_grad)\n",
        "\n",
        "                params_grads = np.array(params_grads).reshape(this_params.shape)\n",
        "\n",
        "                self.params = this_params - lr*params_grads\n",
        "\n",
        "            training_loss = 0\n",
        "            for xi,yi in zip(train_x,train_y):\n",
        "                yhat = self.predict(xi)\n",
        "                training_loss= training_loss + float(bce(yi,yhat))\n",
        "            self.train_loss_series.append(training_loss)# append the train losses values\n",
        "\n",
        "            validation_loss = 0\n",
        "            for xi,yi in zip(valid_x, valid_y):\n",
        "                yhat = self.predict(xi) \n",
        "                validation_loss = validation_loss + float(bce(yi,yhat))\n",
        "            self.valid_loss_series.append(validation_loss) # append the validation losses values\n",
        "\n",
        "    def predict(self, x, logits=False):\n",
        "        yhat=self.params[0] + x.reshape(1, -1) @ self.params[1:].reshape(-1, 1)# reshape x and make it as 1 row (1*2), and for params reshape for one column(2*1)\n",
        "        if not logits:\n",
        "            yhat = self.logistic(yhat)\n",
        "            \n",
        "        return yhat"
      ],
      "metadata": {
        "id": "siIrS2J3Pn0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 5: here I stored the data and used the class\n",
        "\n",
        "How to know if there is overfitting or not?\n",
        "\n",
        "(if the  plot of training loss continues to decrease, while the plot of validation loss decreases to a point and begins increasing again.)\n",
        "\n",
        "For my model all the validation loss points decrease every step----No overfitting\n",
        "\n",
        "I will make a loop to confirm that i don't have any overfitting\n",
        "\n"
      ],
      "metadata": {
        "id": "L8OJTWW5fddw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LR1 = LogisticRegressor(n_features = 2)\n",
        "LR1.fit(train_x, train_y, valid_x, valid_y, lr = 0.3)"
      ],
      "metadata": {
        "id": "UvBCszPpP8La"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(LR1.train_loss_series,label='train loss')\n",
        "plt.plot(LR1.valid_loss_series,label='valid loss')\n",
        "plt.legend (loc='best')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')"
      ],
      "metadata": {
        "id": "UYyM00Ht6KfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to predict if there is an over fit or not \n",
        "valid_loss=valid_loss_series[0]\n",
        "for i in range (1,100):\n",
        "\n",
        "    if valid_loss_series[i]<valid_loss:\n",
        "        valid_loss=valid_loss_series[i]\n",
        "    else:\n",
        "        print('there is an overfit at',i)\n",
        "        break  \n",
        "\n",
        "# if doesnot print i value so no overfit happen  \n",
        "#so No overfitting"
      ],
      "metadata": {
        "id": "PE8oYGAiOZ1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 6"
      ],
      "metadata": {
        "id": "57a7Z6WmTXfG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yhat_test = LR1((test_x))\n",
        "# i made this function to give me the yhat in zero or one\n",
        "def yhat_int (yhat_test):\n",
        "    yhat_int=[]\n",
        "    for i in range(len(yhat_test)): \n",
        "        if yhat_test[i]>=0.5:\n",
        "            yhat_int.append(1)\n",
        "        else:\n",
        "            yhat_int.append(0)\n",
        "    return yhat_int"
      ],
      "metadata": {
        "id": "Lq9liVDKTSj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8s3PzBHhf1S"
      },
      "outputs": [],
      "source": [
        "def perf_measure(test_y, yhat_test):\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    TN = 0\n",
        "    FN = 0\n",
        "    yhat_test=yhat_int (yhat_test)\n",
        "    for i in range(len(yhat_test)): \n",
        "        if test_y[i]==yhat_test[i]==1:\n",
        "           TP += 1\n",
        "        elif test_y[i]==yhat_test[i]==0:\n",
        "           TN += 1\n",
        "        elif yhat_test[i]==1 and test_y[i]!=yhat_test[i]:\n",
        "           FP += 1\n",
        "        elif yhat_test[i]==0 and test_y[i]!=yhat_test[i]:\n",
        "           FN += 1\n",
        "\n",
        "    return(TP, FP, TN, FN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fte-jG_Hhf5C"
      },
      "outputs": [],
      "source": [
        "print(perf_measure(test_y, yhat_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question:7"
      ],
      "metadata": {
        "id": "IrWx6Ch0X27c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPJkSPH-hf6h"
      },
      "outputs": [],
      "source": [
        "#Calculate the precision and recall and F1 score.\n",
        "\n",
        "def precision(y, yhat):\n",
        "# calculate the precision and return it\n",
        "    TP, FP, TN, FN= perf_measure(y, yhat)\n",
        "    precision=float (TP / (FP + TP))\n",
        "\n",
        "    return precision \n",
        "\n",
        "precision(test_y, yhat_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0iAYdluhf-v"
      },
      "outputs": [],
      "source": [
        "\n",
        "def recall(y, yhat):\n",
        "# calculate the recall and return it\n",
        "    TP, FP, TN, FN= perf_measure(y, yhat)\n",
        "    recall= TP / (FN + TP)\n",
        "    return recall\n",
        "recall(test_y, yhat_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AeXNYAeVhgBo"
      },
      "outputs": [],
      "source": [
        "def f_beta(y, yhat, beta=1):\n",
        "    pr = precision(y, yhat)\n",
        "    rc = recall(y, yhat)\n",
        "    f_beta=((1+(beta**2))*(pr*rc)) / (((beta**2)*pr)+rc)\n",
        "    return f_beta\n",
        "\n",
        "f_beta(test_y, yhat_test >=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question: 8"
      ],
      "metadata": {
        "id": "6UFfYo42X_fv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sb6ClmzphhQJ"
      },
      "outputs": [],
      "source": [
        "#TP, FP, TN, FN\n",
        "print ('|\\t \\t|\\t \\t|\\tpredicted\\t|\\t \\t\\t|')\n",
        "print ('|\\t \\t|\\t \\t|\\tpositive\\t|\\tnegative\\t|')\n",
        "print ('|\\tActual\\t|\\tPositive|''\\t',perf_measure(test_y, yhat_test)[0] ,'\\t''\\t|\\t' ,perf_measure(test_y, yhat_test)[3],'\\t\\t|')\n",
        "print ('|\\t\\t|\\tNegative|''\\t',perf_measure(test_y, yhat_test)[1] ,'\\t''\\t|\\t' ,perf_measure(test_y, yhat_test)[2],'\\t\\t|\\n')\n",
        "print ('- Precision:',precision(test_y, yhat_test))\n",
        "print ('- Recall:',recall(test_y, yhat_test))\n",
        "print ('- F_1 Score:',f_beta(test_y, yhat_test >=0.5))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 9:"
      ],
      "metadata": {
        "id": "6CR-U20JYZwl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def roc(y, yhat, threshold_step=0.05):\n",
        "    tp = []\n",
        "    fp=[]  \n",
        "    tpf=[]\n",
        "    fpf=[]  \n",
        "    # iteratively increase the threshold by threshold_step,\n",
        "    thre = 0\n",
        "    for i in range (21):\n",
        "        yhat_n=[] \n",
        "        for i in range(len(yhat)): \n",
        "            if yhat[i]>=thre:\n",
        "                yhat_n.append(1)\n",
        "            else:\n",
        "                yhat_n.append(0)\n",
        "        TP, FP, TN, FN= perf_measure(y, yhat_n)\n",
        "        # calculating the TP and FP rate for each iteration. This function\n",
        "        tp=TP/(TP+FN)\n",
        "        fp=FP/(FP+TN)\n",
        "        # should return two lists, a list of TP rates, and a list of FP\n",
        "        tpf.append(tp)\n",
        "        fpf.append(fp) \n",
        "        thre +=threshold_step   \n",
        "    return (tpf, fpf)\n",
        "\n",
        "\n",
        "tpr_array,fpr_array=(roc(test_y, yhat_test))\n"
      ],
      "metadata": {
        "id": "FqvQH3Vq75_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(fpr_array,tpr_array, 'r')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YqVUQ-Nc8yiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate the area under the curve and approximating the intergral  \n",
        "auc = sum(np.trapz([fpr_array],[tpr_array]))+1\n",
        "print('Area under the curve:',auc)"
      ],
      "metadata": {
        "id": "8GxcHp3rk3im"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 10:\n",
        "using differnt columns"
      ],
      "metadata": {
        "id": "godznLaTZE0t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# first we will define another columns \n",
        "# i will use different columns this times\n",
        "train_x=train_data[['Sepal Width ','Sepal Length']].to_numpy()# this is train data x, I just get the petal width and petal lenght as x \n",
        "train_y=train_data['target'].to_numpy()# take the target value as y\n",
        "\n",
        "valid_x=valid_data[['Sepal Width ','Sepal Length']].to_numpy()\n",
        "valid_y=valid_data['target'].to_numpy()\n",
        "\n",
        "test_x=test_data[['Sepal Width ','Sepal Length']].to_numpy()\n",
        "test_y=test_data['target'].to_numpy()\n"
      ],
      "metadata": {
        "id": "aczrJhZ0ZKmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LR1 = LogisticRegressor(n_features = 2)\n",
        "LR1.fit(train_x, train_y, valid_x, valid_y, lr = 0.3)\n",
        "yhat_test = LR1((test_x))"
      ],
      "metadata": {
        "id": "zQLlvVhFaRal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(perf_measure(test_y, yhat_test))# print (TP, FP, TN, FN)"
      ],
      "metadata": {
        "id": "MxZWyHf3amMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tpr_array,fpr_array=(roc(test_y, yhat_test))"
      ],
      "metadata": {
        "id": "lTsWHWogawev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(fpr_array,tpr_array, 'r')\n",
        "plt.title('After using a differnt columns')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0at836sKa0S0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TP, FP, TN, FN\n",
        "print ('|\\t \\t|\\t \\t|\\tpredicted\\t|\\t \\t\\t|')\n",
        "print ('|\\t \\t|\\t \\t|\\tpositive\\t|\\tnegative\\t|')\n",
        "print ('|\\tActual\\t|\\tPositive|''\\t',perf_measure(test_y, yhat_test)[0] ,'\\t''\\t|\\t' ,perf_measure(test_y, yhat_test)[3],'\\t\\t|')\n",
        "print ('|\\t\\t|\\tNegative|''\\t',perf_measure(test_y, yhat_test)[1] ,'\\t''\\t|\\t' ,perf_measure(test_y, yhat_test)[2],'\\t\\t|\\n')\n",
        "print ('- Precision:',precision(test_y, yhat_test))\n",
        "print ('- Recall:',recall(test_y, yhat_test))\n",
        "print ('- F_1 Score:',f_beta(test_y, yhat_test >=0.5))"
      ],
      "metadata": {
        "id": "Ej8dWw3pbmDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate the area under the curve and approximating the intergral  \n",
        "auc = (np.trapz([fpr_array],[tpr_array]))+1 # using numpy trapozidal \n",
        "print('Area under the curve:', auc)"
      ],
      "metadata": {
        "id": "muCerbzgiQBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "comparing, after using differnt columns we will find that these new two columns better than the first column, which i used\n",
        "\n",
        "because:\n",
        "- Recall: 1.0\n",
        "- F_1 Score: 1.0\n",
        "\n",
        "and the recall, and f_1 score is more than the last one\n",
        "\n",
        "And it can predict all true value, also the area under the curve is equall to 1 and in lecture we said that :\n",
        "\n",
        "If the AUC is close to one we know that the model at any threshold has very good discriminatory power.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DGIXGv84gT7X"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}